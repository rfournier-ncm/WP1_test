---
title: "Model_plots_EMC2"
author: "Fournier RaphaÃ«l"
date: "`r Sys.Date()`"
output: html_document
---

```{r directory}
setwd("~/Rstudio/WP1/WP1")
```



## load packages ##
```{r load-pkg}
pkxg <- c("EMC2", "tidyverse", "RColorBrewer", "patchwork", "tidybayes", "DataExplorer","ggpubr", "paletteer")

lapply(pkxg, library, character.only = TRUE)
```


## plot settings ##

theme settings for ggplot

```{r, eval = F}
theme_set(
  theme_bw() +
    theme(text = element_text(size = 18, face="bold"), 
          title = element_text(size = 18, face="bold"),
          legend.position = "bottom")
)

## Set the amount of dodge in figures
pd <- position_dodge(0.7)
pd2 <- position_dodge(1)
```


#Load models
```{r}
#Preregistered model
load("Exp_1/models/LBA_exp1_v1.RData")
```

#Quick plots
```{r}
#Preregistered model, map = FALSE
plot_pars(LBA_exp1_v1,selection="mu",layout=c(2,5),map = FALSE)
posterior_summary(LBA_exp1_v1,selection="alpha",probs = c(0.025, 0.5, 0.975),map = FALSE)#for each participant
posterior_summary(LBA_exp1_v1,selection="mu",probs = c(0.025, 0.5, 0.975),map = FALSE)#at group level


#Preregistered model, map = TRUE
plot_pars(LBA_exp1_v1,selection="mu",layout=c(2,5),map = TRUE)
posterior_summary(LBA_exp1_v1,selection="alpha",probs = c(0.025, 0.5, 0.975),map = TRUE)#for each participant
posterior_summary(LBA_exp1_v1,selection="mu",probs = c(0.025, 0.5, 0.975),map = TRUE)#at group level
```

#Parameters per subjects
```{r}
#Preregistered model
param_1_pid = EMC2::parameters(LBA_exp1_v1,selection="alpha", N = NULL, resample = TRUE)
#Remember:number of iters = 10000 / number of chains = 3 -> 10'000 x 30(subjects) x 3(number of chains) = 900'000 obs for each parameter
```


###Prergistered model

# section 2 #

## what about visualising parameters from the model? ##

As well as the posterior predictions, we also want to plot and summarise the estimated parameters from the posterior distribution. e.g., drift rate, response caution etc. So let's take a look at that.

Note to Raph/reminder for Rich: One thing that took a little (or rather a lot of) figuring out was how the DMC compare.p convenience function calculates group average parameter estimates for the posterior distribution. It takes all pid posteriors, averages them first and then calculates the relevant quantiles to display and make inferences from. In other words, it first summarises parameters over pid 1, 2, 3, etc. and then calculates quantiles. This matters, because you could also calculate the quantiles without first averaging. So, the below has been tested to produce the same outputs as the compare.p function, which is re-assuring.

But instead of using compare.p, we take the posterior distributions from the samples object and then summarise and plot the results ourselves.

## wrangle all parameters and take a quick look ##

This is just to get a quick overview of all 9 parameters (before we perform any contrasts/comparisons between conditions).

## wrangle the samples first into a tidy format ##

transpose samples and pluck theta out into a list of arrays

## create a group summary distribution ##

summarise across pid (to be consistent with the DMC compare.p function)

##Wrangle
Pid level
```{r}
split_tibble <- function(tibble, col = 'col') tibble %>% split(., .[, col])
array_theta_1 <- split_tibble(param_1_pid, "subjects")
array_theta_1<-do.call(rbind, array_theta_1)
array_theta_pid_1 <- array_theta_1 %>%
  pivot_longer(cols = c("v_SNovel:lMTRUE", "v_SNovel:lMFALSE", "v_SLearned:lMTRUE", "v_SLearned:lMFALSE", "sv_lMTRUE", "B_lRNovel", "B_lRLearned", "A", "t0"), names_to = "param", values_to = "value")%>%
  add_column(datapoint = rep(1:30000,each=9,times=30))%>% #here 30'000 = number of chains (3) x number of iteration (10'000)
  rename(pid=subjects)
```

Average across participants
```{r}
theta_group_1 <- array_theta_pid_1 %>%
  group_by(datapoint,param) %>% 
  summarise(value = mean(value, na.rm = T)) %>% 
  ungroup() %>% 
  add_column(pid = "average") %>% ## add a column which makes clear it is the avg. not needed but useful for plotting later
  relocate(pid, .before = everything())
head(theta_group_1)
glimpse(theta_group_1)
```

## calculate quantiles ##

calculate quantiles per parameter at the group level

```{r}
library(tidybayes)
theta_group_1_q <- theta_group_1 %>%
  group_by(param) %>% 
  median_qi(value)
theta_group_1_q
```

and do the same per pid

```{r}
theta_pid_1_q <- array_theta_pid_1 %>%
  group_by(pid, param) %>% 
  median_qi(value)
theta_pid_1_q

```

## some quick and dirty plots with all of the parameters ##

plot the distribution per parameter using a tidybayes halfeye plot

```{r}
p2.1 <- ggplot(theta_group_1, aes(x = value, y = fct_rev(param))) +  
  stat_halfeye(alpha = 0.9) +
  labs(x = "parameter estimate", y = "") 
p2.1

ggsave("Exp_1/figures/all_params_1.jpeg",
       width = 8, height = 6)
```

plot avg and individual pid parameters

```{r}
p2.2 <- ggplot(theta_group_1, aes(x = value, y = fct_rev(param))) +  
  stat_halfeye(alpha = 0.9, position = position_nudge(y=-0.5)) +
  geom_pointinterval(data = theta_pid_1_q, aes(xmin=.lower, xmax=.upper, 
                                           colour = pid, fill = pid),
                     position = position_dodge(width = 0.7)) +
  labs(x = "parameter estimate", y = "") +
  facet_wrap(~param, scales = "free_y") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
p2.2

ggsave("Exp_1/figures/all_params_pid_1.jpeg",
       width = 8, height = 6)
```

# section 3 #

## plot thresholds separately ##

first, wrangle to make a separate dfs

thresholds df per pid

```{r}
thresh_pid_1 <- array_theta_pid_1 %>% 
  filter(str_detect(param, "B_")) %>% 
  mutate(response = if_else(str_detect(param, "lRfam"), "Learned", "Novel"),
         response = factor(response,
                            levels = c("Novel", "Learned")))
head(thresh_pid_1)
str(thresh_pid_1)
summary(thresh_pid_1)

## data check
thresh_pid_1 %>% 
  distinct(param, response)
```

thresholds at the group level

```{r}
thresh_group_1 <- theta_group_1 %>% 
  filter(str_detect(param, "B_")) %>% 
  mutate(response = if_else(str_detect(param, "lRfam"), "Learned", "Novel"),
         response = factor(response,
                            levels = c("Novel", "Learned")))
head(thresh_group_1)
str(thresh_group_1)
summary(thresh_group_1)
```

## plot ##

at the group level

```{r}
p3.1 <- ggplot(thresh_group_1, aes(x = value, y = fct_rev(response))) +
  stat_halfeye(alpha = 0.7, aes(fill = response)) +
  scale_fill_paletteer_d("rcartocolor::Safe") +
  scale_colour_paletteer_d("rcartocolor::Safe")  +
  labs(y="Response", x="Threshold", title=bquote("Group level: 
Threshold by response")) +
  labs(fill = "Response") +
  theme(legend.position = "none")
p3.1

## save a figure
ggsave("Exp_1/figures/thresh.jpeg",width = 10, height = 6)
```

## caluclate a threshold response key difference ##

per pid

```{r}
thresh_diff_pid_1 <- thresh_pid_1 %>%
  pivot_wider(id_cols = -param,
              names_from = "response",
              values_from = "value") %>% 
  mutate(diff = Novel - Learned)
head(thresh_diff_pid_1)
```

at the group level

```{r}
thresh_diff_1 <- thresh_group_1 %>%
  pivot_wider(id_cols = -param,
              names_from = "response",
              values_from = "value") %>% 
  mutate(diff = Novel - Learned)
head(thresh_diff_1)
```

## quantiles on the difference score ##

per pid

```{r}
thresh_diff_pid_1_q <- thresh_diff_pid_1 %>%
  group_by(pid) %>% 
  median_qi(diff)
thresh_diff_pid_1_q
```

at the group level

```{r}
thresh_diff_1_q <- thresh_diff_1 %>%
  group_by(pid) %>%
  median_qi(diff)
thresh_diff_1_q
```

## plot the threshold difference score ##

plot the average difference
#redo theses plots
```{r}
p3.2 <- ggplot(thresh_diff_1, aes(x = diff, y = "")) +  
  stat_halfeye(alpha = 0.9, fill="firebrick") +
  geom_vline(xintercept = 0, color = "darkgrey") +
  labs(title = "Group level: 
Threshold (Novel > Learned)", 
       x = "Threshold", y="Density") 
p3.2
```

plot individual pids

```{r}
thresh_diff_pid_1$pid = with(thresh_diff_pid_1, reorder(pid, diff, mean))
p3.3 <- ggplot(thresh_diff_pid_1, aes(x = diff, y = pid,
                                    fill=pid)) +  
  stat_halfeye(alpha = 0.7) +
  geom_vline(xintercept = 0, color = "darkgrey") +
  labs(title = "Participant level: Threshold (Novel > Learned)", 
       x = "Threshold", y="participant") 
p3.3
```

plot the average difference and individual pids

```{r}
p3.4 <- ggplot(thresh_diff_1, aes(x = diff, y= reorder(pid, diff, mean))) +  
  stat_halfeye(data = thresh_diff_pid_1,
               alpha = 0.7) +
  geom_vline(xintercept = 0, color = "darkgrey") +
  labs(title = "Individual and average
threshold differences", 
       x = "Threshold", y="participant ID") +
  stat_halfeye(alpha = 0.9, fill="firebrick",
               position = position_nudge(y=0)) 
p3.4
```

## plot together ##

```{r}
p3.5 <- p3.1 / p3.2 | p3.3 +
  labs(caption = "80% and 95% quantile intervals shown in black")
p3.5

# save a figure
 ggsave("Exp_1/figures/thresh.jpeg",
        width = 21, height = 10)
```

and now combine avg and pid difference plots

```{r}
p3.6 <- p3.1 | p3.2 +
  labs(caption = "80% and 95% credible intervals shown in black")
p3.6

# save a figure
ggsave("Exp_1/figures/thresh_2.jpeg",
       width = 15, height = 10)
```

```{r}
p3.6 <- p3.1 | p3.4 +
  labs(caption = "80% and 95% quantile intervals shown in black")
p3.6

# save a figure
ggsave("Exp_1/figures/thresh_3.jpeg",
       width = 21, height = 10)
```


the exact layout, labels of factors and arrangement may need polishing and re-arranging.

But for now, the data seem to be what we want.

# section 4 #

## plot drift rate separately ##

## wrangle ##

create a drift-rate df

```{r}
drift_rate_pid_1 <- array_theta_pid_1 %>% 
  filter(str_detect(param, "v_S")) %>% 
  mutate(condition = if_else(str_detect(param, "Novel"), "Novel", "Learned"),
         accuracy = if_else(str_detect(param, "TRUE"), "True", "False"),
         condition = factor(condition,
                            levels = c("Novel", "Learned")),
         accuracy = factor(accuracy,
                            levels = c("False", "True")))
head(drift_rate_pid_1)
str(drift_rate_pid_1)
summary(drift_rate_pid_1)

## data check
drift_rate_pid_1 %>% 
  distinct(param, condition, accuracy)
```


drift rate at the group level

```{r}
drift_rate_group_1 <- theta_group_1 %>% 
  filter(str_detect(param, "v_S")) %>% 
  mutate(condition = if_else(str_detect(param, "Novel"), "Novel", "Learned"),
         accuracy = if_else(str_detect(param, "TRUE"), "True", "False"),
         condition = factor(condition,
                            levels = c("Novel", "Learned")),
         accuracy = factor(accuracy,
                            levels = c("False", "True")))
head(drift_rate_group_1)
str(drift_rate_group_1)
summary(drift_rate_group_1)
```

## plot ##

#Create a custom manual colour scale: drift_rate group

```{r}
library(RColorBrewer)
myColors_drift <- RColorBrewer::brewer.pal(12, "Dark2")[4:5]
names(myColors_drift) <- levels(drift_rate_group_1$accuracy)
colScale_drift <- scale_fill_manual(name = "Accuracy", values = myColors_drift)
```

the average

```{r}
p4.1 <- ggplot(drift_rate_group_1, aes(x = value, y = fct_rev(condition), 
                               fill = accuracy)) +
  stat_halfeye(alpha = 0.7) +
  colScale_drift +
  labs(title = "Group level: True and False 
drift rate by familiarity condition", y="Familiarity", x="Drift rate") +
  guides(fill = guide_legend(title = "Accuracy"))

p4.1

ggsave("Exp_1/figures/drift_rate_1.jpeg",
        width = 10, height = 6)
```

and now facet by pid

```{r}
p4.2 <- ggplot(drift_rate_pid_1, aes(x = value, y = fct_rev(condition), 
                               fill = accuracy)) +
  stat_halfeye(alpha = 0.7) +
  colScale_drift +
  labs(title = "Participant level: Drift-rate by condition",
       y="condition", x="Drift rate") +
  facet_wrap(~pid)
p4.2
```

take a look together

```{r}
p4.1 / p4.2
ggsave("Exp_1/figures/drift_rate_true_false_1.jpeg", 
       width = 16, height = 13)
```

## caluclate drift rate differences between conditions and accuracy ##

per pid

```{r}
## just true > false differences (accuracy)
drift_acc_diff_pid_1 <- drift_rate_pid_1 %>%
  pivot_wider(id_cols = -param,
               names_from = accuracy,
               values_from = value) %>%
  mutate(diff = True - False)
drift_acc_diff_pid_1

## unf > fam differences
drift_acc_cond_diff_pid_1 <- drift_acc_diff_pid_1 %>%
  pivot_wider(id_cols = -c("True", "False"), 
              names_from = condition,
              values_from = diff) %>%
  mutate(diff = Novel - Learned)
drift_acc_cond_diff_pid_1
```

at the group level

```{r}
## just true > false differences (accuracy)
drift_acc_diff_1 <- drift_rate_group_1 %>%
  pivot_wider(id_cols = -param,
               names_from = accuracy,
               values_from = value) %>%
  mutate(diff = True - False)
drift_acc_diff_1

## unf > fam differences
drift_acc_cond_diff_1 <- drift_acc_diff_1 %>%
  pivot_wider(id_cols = -c("True", "False"), 
              names_from = condition,
              values_from = diff) %>%
  mutate(diff = Novel - Learned)
drift_acc_cond_diff_1
```

## plot the differences ##

differences between true and false, separately for unf and fam


plot

```{r}
p4.3 <- ggplot(drift_acc_diff_1, aes(x = diff, y = fct_rev(condition))) +
  stat_halfeye(aes(fill = condition), alpha = 0.7) +
  scale_fill_paletteer_d("rcartocolor::Safe") +
  scale_colour_paletteer_d("rcartocolor::Safe")  +
  geom_vline(xintercept = 0, color = "darkgrey") +
  theme(legend.position = "none") +
  labs(title = "Group level: Drift rate (True > false)
by familiarity condition",
       x="Drift rate", y="Familiarity") 

p4.3
```

quantiles

```{r}
drift_acc_diff_1_q <- drift_acc_diff_1 %>%
  group_by(condition) %>% 
  median_qi(diff)
drift_acc_diff_1_q
```

difference between unf (true and false) > fam (true > false)

plot

```{r}
p4.4 <- ggplot(drift_acc_cond_diff_1, aes(x = diff, y = "")) +
  stat_halfeye(fill = "firebrick", alpha = 0.9) +
  geom_vline(xintercept = 0, color = "darkgrey") +
  labs(title = "Group level: Drift rate (Novel > Learned)",
       x="Drift rate", y="") +
  xlim(0,3)
p4.4
```

quantiles

```{r}
drift_acc_cond_diff_1_q <- drift_acc_cond_diff_1 %>%
  median_qi(diff)
drift_acc_cond_diff_1_q
```

## plot together ##

```{r}
p4.5 <- p4.3 | p4.4 +
  labs(caption = "80% and 95% credible intervals shown in black")
p4.5

# save a figure
ggsave("Exp_1/figures/drift_rat_mini_1.jpeg",
       width = 15, height = 10)
```

## plot the average difference and pid differences ##

```{r}
drift_acc_cond_diff_pid_1$pid = with(drift_acc_cond_diff_pid_1, reorder(pid, diff, mean))
p4.6 <- ggplot(drift_acc_cond_diff_1, aes(x = diff, y=pid)) +  
  stat_halfeye(alpha = 0.9, fill="firebrick") +
  stat_halfeye(data = drift_acc_cond_diff_pid_1,
               alpha = 0.7) +
  geom_vline(xintercept = 0, color = "darkgrey") +
  labs(title = "Individual and average 
drift rate differences", 
       x = "Drift rate", y="participant ID") 
p4.6
```

## combine drift rate plots ##

```{r}
p4.7 <- p4.3 / p4.4 | p4.6 +
  labs(caption = "80% and 95% quantile intervals shown in black")
p4.7 

# save a figure
ggsave("Exp_1/figures/drift_rate_pid_1.jpeg",
       width = 15, height = 10)
```


## compare threshold and drift rate ##

```{r}
p3.4 | p4.6
```

ok, so the plots need polishing, but they look pretty good.


## Exploratory Analysis ##


### Hit Rate and False Alarm Analysis - D' ###


```{r}
source("dprime_lab.R") # label indiviudal trilas (i.e., rows in a dataframe) as hits, false alarm, or correct rejection

source("dprime_cat.R") # total number of hits, misses, false alarms, and correct rejections for each participant
```

#Load the data
```{r}
data<-read_csv("/Users/rfournier/Rstudio/EMC_WP1_1/EMC_WP1_1/data/data.csv")
theta_pid_1_q <- read_csv("data/theta_pid_1_q.csv")
```



## Learned faces condition

#Calculating HR, FA, MISS AND CR
```{r}
data_prime <- data %>%
  mutate(keys = if_else(keypress == "q", "fam", "unf"),
         keys = as.factor(keys)) %>%
  select(pid,cond,keys,acc) %>%
  rename(correct = acc)


data_prime.dprime <- dprime_lab("cond", "keys", "correct", data = data_prime)
df.cat <- dprime_cat(data_prime.dprime,pid)
```

#Cacluating D prime for every participant
```{r}
dprime <- df.cat %>%
  mutate(hit_rate_fam = Hits/TotalTarg,
         false_alarm_fam = FalseAlarms/TotalDis,
         hit_rate_unf = CorrectRejs/TotalDis,
         false_alarm_unf = Misses/TotalTarg,
         d_prime_fam = qnorm(hit_rate_fam) - qnorm(false_alarm_unf),
         d_prime_unf = qnorm(hit_rate_unf) - qnorm(false_alarm_fam)) %>%
  mutate(pid = as.numeric(as.factor(pid)))%>%
  filter(!false_alarm_fam == 0,
         !pid == "3")

```

#Plotting D prime
```{r}
#D'Fam
d1<-ggplot(dprime, aes(x = false_alarm_fam, y = hit_rate_fam, label = round(d_prime_fam, 2))) +
  geom_text()+
  # xlim(0,1) +
  # ylim(0,1) +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_abline(slope = 1, alpha = .5, color = "red", linetype =2) +
  labs(title = "d' values for Learned faces") +
  xlab("False alarm rate") +
  ylab("Hit rate")
d1
ggsave("figures/d'_learned.jpeg")
```
#D'Unf
```{r}
d2 <- ggplot(dprime, aes(x = false_alarm_unf, y = hit_rate_unf, label = round(d_prime_unf, 2))) +
  geom_text()+
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_abline(slope = 1, alpha = .5, color = "red", linetype =2) +
  labs(title = "d' values for New faces") +
  xlab("False alarm rate") +
  ylab("Hit rate")
d2
ggsave("figures/d'_new.jpeg")
```


## Correlation D' - Drift rate ##

#Organize theta pid
```{r}
theta_pid_1_q <- theta_pid_1_q %>%
  mutate(pid = as.numeric(as.factor(pid)))
theta_pid_1_q
```

#Compute and plot correlation: D' - Drift rate diff.
```{r}
#More wrangle for correlations plotting
test <- theta_pid_1_q %>%
  select(pid,param,value) %>%
  pivot_wider(names_from = param, values_from = value)
drift_corr <- test %>%
  select(pid,v_Sfam_lMFALSE,v_Sfam_lMTRUE,v_Sunf_lMFALSE,v_Sunf_lMTRUE) %>%
  mutate(diff_fam = v_Sfam_lMTRUE - v_Sfam_lMFALSE,
         diff_unf = v_Sunf_lMTRUE - v_Sunf_lMFALSE) %>%
  select(pid,diff_fam,diff_unf) %>%
  mutate(pid = as.numeric(as.factor(pid))) %>%
  filter(!is.na(diff_fam),
         !pid == "1",
         !pid == "27")
drift_corr$d_prime_fam = dprime$d_prime_fam  
drift_corr$d_prime_unf = dprime$d_prime_unf
head(drift_corr)
```

Diff D' unf/fam
```{r}
#More wrangle for D' plotting
d_plot <- drift_corr %>%
  select(pid, d_prime_unf, d_prime_fam) %>%
  rename(Learned = "d_prime_fam", New = "d_prime_unf") %>%
  pivot_longer(!pid, names_to = "cond", values_to = "D") %>%
  group_by(cond) %>%
  median_qi(D) %>% 
  mutate(sd = sd(D))%>% 
  ggplot(aes(cond, D, fill = cond)) +
    geom_errorbar(aes(cond, ymin = D-sd, ymax = D+sd), width = 0.4, colour= "black", alpha = .9) +
    geom_col() +
    xlab("Condition") +
    ylab("d'") +
    labs(title = "d' per condition") +
    ylim(-1,5) 
d_plot
ggsave("figures/d_plot_comp.jpeg")
```

Corr plots
```{r}
#Learned faces
drift_corr <- drift_corr %>%
  rename(dprime_Learned = "d_prime_fam", dprime_New = "d_prime_unf", Drift_rate_Learned = "diff_fam", Drift_rate_New = "diff_unf")
mat_cor<-plot_correlation(drift_corr[2:5])
mat_cor
ggsave("figures/mat_cor.jpeg")
c1 <- ggplot(drift_corr, aes(x = Drift_rate_Learned, y = dprime_Learned)) +
  geom_point() +
  geom_smooth(method = 'lm', formula = y~x)+
  labs(title = "Learned faces: Correlation between sensitivity (D') 
and accumulation of evidence (Drift rate)") +
  xlab("Drift rate for Learned faces")+
  ylab("D' for Learned faces") +
  stat_cor(method = "pearson")
c1
ggsave("figures/learned_corr.jpeg", width = 10, height = 6)
#New faces
c2 <- ggplot(drift_corr, aes(x = Drift_rate_New, y = dprime_New)) +
  geom_point() +
  geom_smooth(method = 'lm', formula = y~x)+
  labs(title = "New faces: Correlation between sensitivity (D') 
and accumulation of evidence (Drift rate)") +
  xlab("Drift rate for New faces")+
  ylab("D' for New faces")+
  stat_cor(method = "pearson")
c2
ggsave("figures/new_corr.jpeg", width = 10, height = 6)
```
Corr plot TRUE-FALSE
```{r}
test_2 <- theta_pid_1_q %>%
  select(pid,param,value) %>%
  pivot_wider(names_from = param, values_from = value)
drift_corr_2 <- test_2 %>%
  select(pid,v_Sfam_lMFALSE,v_Sfam_lMTRUE,v_Sunf_lMFALSE,v_Sunf_lMTRUE) %>%
  rename(drift_learned_TRUE = "v_Sfam_lMTRUE", drift_learned_FALSE = "v_Sfam_lMFALSE", drift_new_TRUE = "v_Sunf_lMTRUE", drift_new_FALSE = "v_Sunf_lMFALSE") %>%
  mutate(pid = as.numeric(as.factor(pid))) %>%
  filter(!is.na(drift_learned_TRUE),
         !pid == "1",
         !pid == "27")
drift_corr_2$d_prime_fam = dprime$d_prime_fam  
drift_corr_2$d_prime_unf = dprime$d_prime_unf
head(drift_corr_2)

drift_corr_2 <- drift_corr_2 %>%
  rename(dprime_Learned = "d_prime_fam", dprime_New = "d_prime_unf")
mat_cor<-plot_correlation(drift_corr_2[2:7])
mat_cor
ggsave("figures/mat_cor_T_F.jpeg")

```
### Criterion analysis (correlation with the bias parameter)
```{r}

```













